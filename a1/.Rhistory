# to delete the subset from superset as superset will have subset
subset.association.rules. = association.rules[-subset.rules]
length(subset.association.rules.)
#to identify what people buys before buying decoration
decoration.association.rules =
apriori(transactions, parameter = list(supp=0.001, conf=0.8),appearance = list(default="lhs",rhs="DECORATION"))
inspect(head(decoration.association.rules))
#to identify what people buys when they buy metal
metal.association.rules =
apriori(transactions, parameter = list(supp=0.001, conf=0.8),appearance = list(lhs="METAL",default="rhs"))
inspect(head(metal.association.rules))
# create vector of top 10 rules for Visualization
toprules = subset.association.rules.[1:10]
inspect(head(toprules))
#Visualization
plot(subset.association.rules.)
#items havinghigher lift have low support
plot(subset.association.rules.,method="two-key plot")
#order defines number of items
#graph will help to visualize rules better
plot(toprules, method="graph")
plot(toprules, method="graph", engine = "htmlwidget")
#to plot parallel coordinate plot to visualize sales pattern
toprules_lift = head(association.rules, n=20, by ="lift")
plot(toprules_lift, method="paracoord")
#installing packages
install.packages("tidyverse")
install.packages("readxl")
install.packages("knitr")
install.packages("ggplot2")
install.packages("lubridate")
install.packages("arules")
install.packages("arulesViz")
install.packages("plyr")
install.packages("RColorBrewer")
#loading packages
library(tidyverse)     #designed for data science ->statistics
library(readxl)        # to read excel files
library(knitr)         # to identify default settings if not satisfied
library(ggplot2)       # for plotting graphs
library(lubridate)     # to work on date and time format
library(arules)        # for association rules and apriori algorithm functions
library(arulesViz)     # for visualization of association rules and apriori algorithm like plots
library(plyr)          # splitting and combining data
library(dplyr)         # for data manipulation
library(RColorBrewer)  # for color palette
retail = read_excel("C:/rprogramming/Online Retail.xlsx")
?complete.cases
retail = retail[complete.cases(retail),]
retail
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using retail[,]
retail %>% mutate(Description = as.factor(Description))
retail %>% mutate(Country = as.factor(Country))
retail$Date = as.Date(retail$InvoiceDate)
retail$Date
retail$Time = format(retail$InvoiceDate,"%H:%M:%S")
retail$Time
retail$InvoiceNo = as.numeric(as.character(retail$InvoiceNo))
retail$InvoiceNo
glimpse(retail)
#time at which people often purchase
retail$Time = as.factor(retail$Time)
retail$Time
retail
retail$Time1 = format(retail$InvoiceDate,"%H")
retail$Time1
ggplot(retail,aes(x=Time1)) + geom_histogram(stat = "count", fill = "indianred")
# how many items customer buy
detach("package:plyr", unload=TRUE)
retail %>%
group_by(InvoiceNo) %>%
summarize(n_items = mean(Quantity)) %>%
ggplot(aes(x=n_items))+
geom_histogram(fill="indianred", bins = 100000) +
geom_rug()+
coord_cartesian(xlim=c(0,80))
# top 10 best seller products
best_seller = retail %>%
group_by(StockCode, Description) %>%
summarize(count = n()) %>%
arrange(desc(count))
best_seller = head(best_seller,10)
best_seller
best_seller %>%
ggplot(aes(x=reorder(Description,count), y=count))+
geom_bar(stat="identity",fill="indian red")+
coord_flip()
library(plyr)
#to create list onf items that are bought together
itemList = ddply,(retail,c("InvoiceNo","Date"),
function(df1)paste(df1$Description,
collapse = ","))
# paste() concatenates vectors to character and separated results using collapse
itemList$InvoiceNo = NULL
itemList$Date = NULL
#rename column
colnames(itemList) = c("items")
write.csv(itemList,"C:/rprogramming/market_basket.csv", quote = FALSE, row.names = TRUE)
transactions =
read.transactions('C:/rprogramming/market_basket.csv', format = 'basket', sep=',')
summary(transactions)
#graph for top 20 itemsets that are brought frequently
itemFrequencyPlot(transactions,topN=20,type="absolute",
col=brewer.pal(8,'Pastel2'),
main="Absolute Item Frequency Plot")
#graph for top 20 itemsets that are brought frequently relative to other items
itemFrequencyPlot(transactions,topN=20,
type="relative",
col=brewer.pal(8,'Pastel2'),
main="Relative Item Frequency Plot")
#relative frequency will help to know the items that are brought infrequently w.r.t to others
#Now using Association rules and apriori algo for analysis
association.rules =
apriori(transactions, parameter = list(supp=0.001, conf=0.8,maxlen=10))
summary(association.rules)
inspect(association.rules[1:10])
subset.rules =
which(colSums(is.subset(association.rules, association.rules)) > 1)
# get subset rules in vector
"which() returns the position of elements in the vector for which value is TRUE.
colSums() forms a row and column sums for dataframes and numeric arrays.
is.subset() Determines if elements of one vector contain all the elements of other
"
length(subset.rules)
# to delete the subset from superset as superset will have subset
subset.association.rules. = association.rules[-subset.rules]
length(subset.association.rules.)
#to identify what people buys before buying decoration
decoration.association.rules =
apriori(transactions, parameter = list(supp=0.001, conf=0.8),appearance = list(default="lhs",rhs="DECORATION"))
inspect(head(decoration.association.rules))
#to identify what people buys when they buy metal
metal.association.rules =
apriori(transactions, parameter = list(supp=0.001, conf=0.8),appearance = list(lhs="METAL",default="rhs"))
inspect(head(metal.association.rules))
# create vector of top 10 rules for Visualization
toprules = subset.association.rules.[1:10]
inspect(head(toprules))
#Visualization
plot(subset.association.rules.)
#items havinghigher lift have low support
plot(subset.association.rules.,method="two-key plot")
#order defines number of items
#graph will help to visualize rules better
plot(toprules, method="graph")
plot(toprules, method="graph", engine = "htmlwidget")
#to plot parallel coordinate plot to visualize sales pattern
toprules_lift = head(association.rules, n=20, by ="lift")
plot(toprules_lift, method="paracoord")
install.packages("ggplot2")
install.packages("lubridate")
install.packages("arules")
install.packages("plyr")
install.packages("RColorBrewer")
install.packages("plyr")
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
(prc)
prc<- prc[-1]
table(prc$diagnosis_result)
table(prc$diagnosis_result)  # it helps us to get the numbers of patients
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
#This command imports the required data set and saves it to the prc data frame.
#stringsAsFactors = FALSE   #This command helps to convert every character vector
#to a factor wherever it makes sense.
prc<-read.csv("Prostate_Cancer.csv",stringsAsFactors = FALSE)
# to see whether the data is structured or not.
str(prc)
#data is structured with 10 variables and 100 observations. If we observe the
#data set, the first variable 'id' is unique in nature and can be removed as it
#does not provide useful information
##removes the first variable(id) from the data set.
prc<- prc[-1]
#The data set contains patients who have been diagnosed with either Malignant (M) or Benign (B) cancer
table(prc$diagnosis_result)  # it helps us to get the numbers of patients
table(prc$diagnosis)
table(prc$diagnosis)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
str(prc)
prc<- prc[-1]
table(prc$diagnosis)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
str(prc)
prc<- prc[-1]
table(prc$diagnosis)
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
str(prc)
prc<- prc[-1]
table(prc$diagnosis_result)
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
#This command imports the required data set and saves it to the prc data frame.
#stringsAsFactors = FALSE   #This command helps to convert every character vector
#to a factor wherever it makes sense.
prc<-read.csv("Prostate_Cancer.csv",stringsAsFactors = FALSE)
# to see whether the data is structured or not.
str(prc)
#data is structured with 10 variables and 100 observations. If we observe the
#data set, the first variable 'id' is unique in nature and can be removed as it
#does not provide useful information
##removes the first variable(id) from the data set.
prc<- prc[-1]
#The data set contains patients who have been diagnosed with either Malignant (M) or Benign (B) cancer
table(prc$diagnosis_result)  # it helps us to get the numbers of patients
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
str(prc)
prc<- prc[-1]
table(prc$diagnosis_result)
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
#it gives the result in the percentage form rounded of to 1 decimal place( and so it's digits = 1)
round(prop.table(table(prc$diagnosis)) * 100, digits = 1)
#to normalize the data and transform all the values to a common scale.
normalize<- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
# to normalize the numeric features in the data set. Instead of normalizing each of the 8 individual
#variables we use:
prc_n<-as.data.frame(lapply(prc[2:9], normalize))
summary(prc_n$radius)
#Creating training and test data set
#divide the data set into 2 portions in the ratio of 65: 35 (assumed) for the training
#and test data set respectively.
#divide the prc_n data frame into prc_train and prc_test data frames.
#A blank value in each of the below statements indicate that all rows
#and columns should be included.
prc_train<- prc_n[1:65,]
prc_test<- prc_n[66:100,]
#take the diagnosis factor in column 1 of the prc data frame and on turn creates prc_train_labels
#and prc_test_labels data frame.
prc_train_labels<- prc[1:65, 1]
prc_test_labels<- prc[66:100, 1]
#Theknn () function needs to be used to train a model for which we need to
#install a package 'class'. The knn() function identifies the
#k-nearest neighbors using Euclidean distance where k is a user-specified number.
install.packages(class)
library(class)
prc_test_pred<- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=10, prob=T)
#Evaluate model performance
install.packages("gmodels")
library(gmodels)
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq=FALSE)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
#This command imports the required data set and saves it to the prc data frame.
#stringsAsFactors = FALSE   #This command helps to convert every character vector
#to a factor wherever it makes sense.
prc<-read.csv("Prostate_Cancer.csv",stringsAsFactors = FALSE)
# to see whether the data is structured or not.
str(prc)
#data is structured with 10 variables and 100 observations. If we observe the
#data set, the first variable 'id' is unique in nature and can be removed as it
#does not provide useful information
##removes the first variable(id) from the data set.
prc<- prc[-1]
#The data set contains patients who have been diagnosed with either Malignant (M) or Benign (B) cancer
table(prc$diagnosis_result)  # it helps us to get the numbers of patients
#In case we wish to rename B as"Benign" and M as "Malignant" and see the results in the count form
#form, we may write as:
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
#it gives the result in the percentage form rounded of to 1 decimal place( and so it's digits = 1)
round(prop.table(table(prc$diagnosis)) * 100, digits = 1)
#to normalize the data and transform all the values to a common scale.
normalize<- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
# to normalize the numeric features in the data set. Instead of normalizing each of the 8 individual
#variables we use:
prc_n<-as.data.frame(lapply(prc[2:9], normalize))
summary(prc_n$radius)
#Creating training and test data set
#divide the data set into 2 portions in the ratio of 65: 35 (assumed) for the training
#and test data set respectively.
#divide the prc_n data frame into prc_train and prc_test data frames.
#A blank value in each of the below statements indicate that all rows
#and columns should be included.
prc_train<- prc_n[1:65,]
prc_test<- prc_n[66:100,]
#take the diagnosis factor in column 1 of the prc data frame and on turn creates prc_train_labels
#and prc_test_labels data frame.
prc_train_labels<- prc[1:65, 1]
prc_test_labels<- prc[66:100, 1]
#Theknn () function needs to be used to train a model for which we need to
#install a package 'class'. The knn() function identifies the
#k-nearest neighbors using Euclidean distance where k is a user-specified number.
install.packages(class)
library(class)
prc_test_pred<- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=10, prob=T)
#Evaluate model performance
install.packages("gmodels")
library(gmodels)
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq=FALSE)
install.packages("gmodels")
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
#This command imports the required data set and saves it to the prc data frame.
#stringsAsFactors = FALSE   #This command helps to convert every character vector
#to a factor wherever it makes sense.
prc<-read.csv("Prostate_Cancer.csv",stringsAsFactors = FALSE)
# to see whether the data is structured or not.
str(prc)
#data is structured with 10 variables and 100 observations. If we observe the
#data set, the first variable 'id' is unique in nature and can be removed as it
#does not provide useful information
##removes the first variable(id) from the data set.
prc<- prc[-1]
#The data set contains patients who have been diagnosed with either Malignant (M) or Benign (B) cancer
table(prc$diagnosis_result)  # it helps us to get the numbers of patients
#In case we wish to rename B as"Benign" and M as "Malignant" and see the results in the count form
#form, we may write as:
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
#it gives the result in the percentage form rounded of to 1 decimal place( and so it's digits = 1)
round(prop.table(table(prc$diagnosis)) * 100, digits = 1)
#to normalize the data and transform all the values to a common scale.
normalize<- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
# to normalize the numeric features in the data set. Instead of normalizing each of the 8 individual
#variables we use:
prc_n<-as.data.frame(lapply(prc[2:9], normalize))
summary(prc_n$radius)
#Creating training and test data set
#divide the data set into 2 portions in the ratio of 65: 35 (assumed) for the training
#and test data set respectively.
#divide the prc_n data frame into prc_train and prc_test data frames.
#A blank value in each of the below statements indicate that all rows
#and columns should be included.
prc_train<- prc_n[1:65,]
prc_test<- prc_n[66:100,]
#take the diagnosis factor in column 1 of the prc data frame and on turn creates prc_train_labels
#and prc_test_labels data frame.
prc_train_labels<- prc[1:65, 1]
prc_test_labels<- prc[66:100, 1]
#Theknn () function needs to be used to train a model for which we need to
#install a package 'class'. The knn() function identifies the
#k-nearest neighbors using Euclidean distance where k is a user-specified number.
install.packages(class)
library(class)
prc_test_pred<- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=10, prob=T)
#Evaluate model performance
library(gmodels)
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq=FALSE)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
str(prc)
prc<- prc[-1]
table(prc$diagnosis_result)
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
#it gives the result in the percentage form rounded of to 1 decimal place( and so it's digits = 1)
round(prop.table(table(prc$diagnosis)) * 100, digits = 1)
#to normalize the data and transform all the values to a common scale.
normalize<- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
# to normalize the numeric features in the data set. Instead of normalizing each of the 8 individual
#variables we use:
prc_n<-as.data.frame(lapply(prc[2:9], normalize))
summary(prc_n$radius)
#Creating training and test data set
#divide the data set into 2 portions in the ratio of 65: 35 (assumed) for the training
#and test data set respectively.
#divide the prc_n data frame into prc_train and prc_test data frames.
#A blank value in each of the below statements indicate that all rows
#and columns should be included.
prc_train<- prc_n[1:65,]
prc_test<- prc_n[66:100,]
#take the diagnosis factor in column 1 of the prc data frame and on turn creates prc_train_labels
#and prc_test_labels data frame.
prc_train_labels<- prc[1:65, 1]
prc_test_labels<- prc[66:100, 1]
#Theknn () function needs to be used to train a model for which we need to
#install a package 'class'. The knn() function identifies the
#k-nearest neighbors using Euclidean distance where k is a user-specified number.
install.packages(class)
library(class)
prc_test_pred<- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=10, prob=T)
#Evaluate model performance
library(gmodels)
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq=FALSE)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
#This command imports the required data set and saves it to the prc data frame.
#stringsAsFactors = FALSE   #This command helps to convert every character vector
#to a factor wherever it makes sense.
prc<-read.csv("Prostate_Cancer.csv",stringsAsFactors = FALSE)
# to see whether the data is structured or not.
str(prc)
#data is structured with 10 variables and 100 observations. If we observe the
#data set, the first variable 'id' is unique in nature and can be removed as it
#does not provide useful information
##removes the first variable(id) from the data set.
prc<- prc[-1]
#The data set contains patients who have been diagnosed with either Malignant (M) or Benign (B) cancer
table(prc$diagnosis_result)  # it helps us to get the numbers of patients
#In case we wish to rename B as"Benign" and M as "Malignant" and see the results in the count form
#form, we may write as:
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
#it gives the result in the percentage form rounded of to 1 decimal place( and so it's digits = 1)
round(prop.table(table(prc$diagnosis)) * 100, digits = 1)
#to normalize the data and transform all the values to a common scale.
normalize<- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
# to normalize the numeric features in the data set. Instead of normalizing each of the 8 individual
#variables we use:
prc_n<-as.data.frame(lapply(prc[2:9], normalize))
summary(prc_n$radius)
#Creating training and test data set
#divide the data set into 2 portions in the ratio of 65: 35 (assumed) for the training
#and test data set respectively.
#divide the prc_n data frame into prc_train and prc_test data frames.
#A blank value in each of the below statements indicate that all rows
#and columns should be included.
prc_train<- prc_n[1:65,]
prc_test<- prc_n[66:100,]
#take the diagnosis factor in column 1 of the prc data frame and on turn creates prc_train_labels
#and prc_test_labels data frame.
prc_train_labels<- prc[1:65, 1]
prc_test_labels<- prc[66:100, 1]
#Theknn () function needs to be used to train a model for which we need to
#install a package 'class'. The knn() function identifies the
#k-nearest neighbors using Euclidean distance where k is a user-specified number.
install.packages(class)
library(class)
prc_test_pred<- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=10, prob=T)
#Evaluate model performance
library(gmodels)
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq=FALSE)
setwd("C:/Users/ASUS/Desktop/PR Lab/a1")
prc<-read.csv("Breast_Cancer.csv",stringsAsFactors = FALSE)
str(prc)
prc<- prc[-1]
table(prc$diagnosis_result)
prc$diagnosis<- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
round(prop.table(table(prc$diagnosis)) * 100, digits = 1)
normalize<- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
prc_n<-as.data.frame(lapply(prc[2:9], normalize))
summary(prc_n$radius)
prc_train<- prc_n[1:65,]
prc_test<- prc_n[66:100,]
prc_train_labels<- prc[1:65, 1]
prc_test_labels<- prc[66:100, 1]
install.packages(class)
library(class)
prc_test_pred<- knn(train = prc_train, test = prc_test,cl = prc_train_labels, k=10, prob=T)
#Evaluate model performance
library(gmodels)
CrossTable(x = prc_test_labels, y = prc_test_pred,prop.chisq=FALSE)
#inserting data
sales <- read.csv("C:/Users/ASUS/Desktop/PR Lab/a1/yearly_sales.csv")
head(sales)
summary(sales)
#plotting graph
plot(sales$num_of_orders,sales$sales_total,
main = "Number of Orders vs. Sales")
results <- lm(sales$sales_total ~ sales$num_of_orders)
summary(results)
hist(results$residuals, breaks = 800)
#writing to new file
df <- read.csv("C:/Users/ASUS/Desktop/PR Lab/a1/yearly_sales.csv")
print (df)
write.csv(df,"C:/Users/ASUS/Desktop/PR Lab/a1/write.csv", row.names = FALSE)
#vector
vector <- read.csv('C:/Users/ASUS/Desktop/PR Lab/a1/write.csv')
v1 <- vector[[1]]  # by column number
v2 <- vector[["cust_id"]]  # by column name
v3 <- vector$cust_id  # by column name
print (v3)
#Arrays
result <- array(c(v3),dim = c(3,3,2))
print(result)
#matrix
mat <- as.matrix(df)
class(mat)
str(mat)
nrow(mat)
ncol(mat)
mat[1, 1]
mat[1:4, 1:2]
#inserting data
sales <- read.csv("C:/Users/ASUS/Desktop/PR Lab/a1/yearly_sales.csv")
head(sales)
summary(sales)
#plotting graph
plot(sales$num_of_orders,sales$sales_total,
main = "Number of Orders vs. Sales")
results <- lm(sales$sales_total ~ sales$num_of_orders)
summary(results)
hist(results$residuals, breaks = 800)
#writing to new file
df <- read.csv("C:/Users/ASUS/Desktop/PR Lab/a1/yearly_sales.csv")
print (df)
write.csv(df,"C:/Users/ASUS/Desktop/PR Lab/a1/write.csv", row.names = FALSE)
#vector
vector <- read.csv('C:/Users/ASUS/Desktop/PR Lab/a1/write.csv')
v1 <- vector[[1]]  # by column number
v2 <- vector[["cust_id"]]  # by column name
v3 <- vector$cust_id  # by column name
print (v3)
#Arrays
result <- array(c(v3),dim = c(3,3,2))
print(result)
#matrix
mat <- as.matrix(df)
class(mat)
str(mat)
nrow(mat)
ncol(mat)
mat[1, 1]
mat[1:4, 1:2]
